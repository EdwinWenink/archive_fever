_id: 82832090-91f8-11ea-a16d-e7b30751e183
_parent: 49-russell_ai_technocracy_surveillance
name: Edwin
reply_to: 17de9370-91f1-11ea-a16d-e7b30751e183
body: "I think that a link between law and morality is desirable but not necessarily the case.\r\nIf I understand that \"rule of recognition\" correctly, it amounts to saying something like: any rule/law is valid within a legal system if it is recognized by the (legal) community as law (thereby heavily relying on common social practice and convention?).\r\nI'm probably missing some nuance there (or it's just completely off), so please correct me if I'm wrong, but then the moral value of a law would depend on the moral quality of the legal community recognizing it as a law.\r\nIn that sense, I don't see why \"rule by AI\" would be incompatible with the \"rule of recognition\", especially if we assume that what those AI technologies do is optimize for the objectives that we provide to them.\r\nThe question then is rather whether that objective is legal or illegal.\r\n\r\nBut in any case, when it comes to providing those objectives, I don't think looking at the legal side of things is sufficiently.\r\nFirst of all, especially in the case of the many technological innovations in AI law is lagging behind moral issues \\*, but secondly, the morally relevant question I tried to point to in the post is whether optimizing for *any* explicit objective measure using AI is a desirable approach, irregardless of whether the \"purpose put into the machine\" is legal or illegal.\r\n\r\nI didn't have the scenario in mind where AI is used to make law by taking human behavior as input. I'm not aware of people proposing this, but of course it's an interesting thought experiment to consider. You could argue that those laws would encode the factual mores of a population - ipso facto it should be recognized -  but I would immediately counter that both morality and law concern what you *ought* to do, not what people in fact do.\r\nE.g. if the majority suddenly starts knifing people, will this AI allow knifing by law, simply because most people seem to think it's okay? \r\nYou could argue this rule could perhaps pass the \"rule of recognition\", but this again shows the potential divergence between legal legitimacy and morality (assuming that you surely would not call \"knifing people\" morally acceptable).\r\n\r\nI indeed had the view in mind where AI becomes a tool for enforcing behavior, rather than the issue of legitimacy. \r\nUses of AI may not be illegal and may be considered legitimate (people got used to it?); but it's morally disconcerting even when there may not yet be relevant laws to address that concern in all scenarios.\r\n\r\n\\* To use a \"stokpaardje\", think about how self-driving cars challenge the current legal framework.\r\n\r\nThanks for the compliment!"
date: 1589030712
